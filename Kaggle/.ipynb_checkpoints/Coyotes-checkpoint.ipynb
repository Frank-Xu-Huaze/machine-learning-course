{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import Model\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# loading training data\n",
    "x_train = []\n",
    "for i in range(1500):\n",
    "    im = Image.open(cwd + '/training/{}.tif'.format(i))\n",
    "    x_train.append(np.asarray(im))\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = np.genfromtxt(cwd + '/labels_training.csv', delimiter=',', skip_header = 1)\n",
    "y_train = y_train.T[1]\n",
    "\n",
    "# loading testing data\n",
    "x_test = []\n",
    "for i in range(1500,2058):\n",
    "    im = Image.open(cwd + '/testing/{}.tif'.format(i))\n",
    "    x_test.append(np.asarray(im))\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras_applications/mobilenet.py:207: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "# Download model weights\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "# Re-structure model\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024, activation='relu')(x) #add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024, activation='relu')(x) #dense layer 2\n",
    "x=Dense(512, activation='relu')(x) #dense layer 3\n",
    "preds=Dense(1, activation='sigmoid')(x) #final layer with sigmoid activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i,layer in enumerate(model.layers):\\n    print(i,layer.name)\\n\\nfrom keras import backend as K\\n\\ndef sensitivity(y_true, y_pred):\\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\\n    return true_positives / (possible_positives + K.epsilon())\\n\\ndef specificity(y_true, y_pred):\\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\\n    return true_negatives / (possible_negatives + K.epsilon())\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 1.8939 - acc: 0.7342 - val_loss: 0.3785 - val_acc: 0.9133\n",
      "Epoch 2/30\n",
      "1200/1200 [==============================] - 37s 30ms/step - loss: 0.1794 - acc: 0.9583 - val_loss: 0.4974 - val_acc: 0.9100\n",
      "Epoch 3/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0619 - acc: 0.9842 - val_loss: 0.5300 - val_acc: 0.9133\n",
      "Epoch 4/30\n",
      "1200/1200 [==============================] - 37s 30ms/step - loss: 0.0433 - acc: 0.9908 - val_loss: 0.7893 - val_acc: 0.9167\n",
      "Epoch 5/30\n",
      "1200/1200 [==============================] - 37s 31ms/step - loss: 0.0429 - acc: 0.9908 - val_loss: 0.8927 - val_acc: 0.9200\n",
      "Epoch 6/30\n",
      "1200/1200 [==============================] - 37s 30ms/step - loss: 0.0483 - acc: 0.9900 - val_loss: 1.0277 - val_acc: 0.8567\n",
      "Epoch 7/30\n",
      "1200/1200 [==============================] - 37s 30ms/step - loss: 0.0392 - acc: 0.9892 - val_loss: 0.5275 - val_acc: 0.9500\n",
      "Epoch 8/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7446 - val_acc: 0.9400\n",
      "Epoch 9/30\n",
      "1200/1200 [==============================] - 37s 31ms/step - loss: 0.0287 - acc: 0.9950 - val_loss: 0.6386 - val_acc: 0.8733\n",
      "Epoch 10/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0666 - acc: 0.9842 - val_loss: 1.0426 - val_acc: 0.9300\n",
      "Epoch 11/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0494 - acc: 0.9875 - val_loss: 1.6786 - val_acc: 0.9100\n",
      "Epoch 12/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0391 - acc: 0.9942 - val_loss: 1.1144 - val_acc: 0.9233\n",
      "Epoch 13/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0238 - acc: 0.9950 - val_loss: 0.9730 - val_acc: 0.9433\n",
      "Epoch 14/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0158 - acc: 0.9942 - val_loss: 1.2873 - val_acc: 0.9400\n",
      "Epoch 15/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0131 - acc: 0.9983 - val_loss: 1.3109 - val_acc: 0.9367\n",
      "Epoch 16/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0041 - acc: 0.9983 - val_loss: 0.8944 - val_acc: 0.9433\n",
      "Epoch 17/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0134 - acc: 0.9950 - val_loss: 1.3039 - val_acc: 0.9300\n",
      "Epoch 18/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.7516 - val_acc: 0.9533\n",
      "Epoch 19/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0320 - acc: 0.9967 - val_loss: 0.5547 - val_acc: 0.9567\n",
      "Epoch 20/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0263 - acc: 0.9942 - val_loss: 0.3725 - val_acc: 0.9667\n",
      "Epoch 21/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4096 - val_acc: 0.9667\n",
      "Epoch 22/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0016 - acc: 0.9992 - val_loss: 0.4303 - val_acc: 0.9600\n",
      "Epoch 23/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 2.5091e-04 - acc: 1.0000 - val_loss: 0.3956 - val_acc: 0.9633\n",
      "Epoch 24/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 9.2099e-05 - acc: 1.0000 - val_loss: 0.3155 - val_acc: 0.9733\n",
      "Epoch 25/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 9.8572e-05 - acc: 1.0000 - val_loss: 0.3168 - val_acc: 0.9733\n",
      "Epoch 26/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 3.0916e-05 - acc: 1.0000 - val_loss: 0.3201 - val_acc: 0.9733\n",
      "Epoch 27/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 9.2534e-04 - acc: 1.0000 - val_loss: 0.4016 - val_acc: 0.9600\n",
      "Epoch 28/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0237 - acc: 0.9950 - val_loss: 0.3010 - val_acc: 0.9567\n",
      "Epoch 29/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.2679 - val_acc: 0.9600\n",
      "Epoch 30/30\n",
      "1200/1200 [==============================] - 36s 30ms/step - loss: 0.0348 - acc: 0.9942 - val_loss: 0.4611 - val_acc: 0.9533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4d1c9cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 50\n",
    "epochs = 30\n",
    "\n",
    "# defining class weights by different number of classes\n",
    "class_weight={1: (len(y_train) - np.sum(y_train)) / np.sum(y_train),\n",
    "              0: 1}\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          class_weight=class_weight,\n",
    "          verbose=1,\n",
    "          validation_split = 0.2)\n",
    "\n",
    "# The fitting process will take about 20~40 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and writting CSVs\n",
    "y = model.predict(x_test)\n",
    "df = pd.DataFrame({'id':np.arange(1500, 2058, 1),\n",
    "                  'score':y.T[0]})\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
